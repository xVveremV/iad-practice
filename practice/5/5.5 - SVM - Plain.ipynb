{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300\n",
    "\n",
    "a1 = 1\n",
    "b1 = 3\n",
    "\n",
    "a2 = 2\n",
    "b2 = 5\n",
    "\n",
    "x = np.random.uniform(0, 5, N)\n",
    "noise = np.random.normal(0, 1, N)\n",
    "\n",
    "y1base = a1 * x + b1\n",
    "y2base = a2 * x + b2\n",
    "\n",
    "y1 = y1base + noise\n",
    "y2 = y2base + noise\n",
    "\n",
    "plt.grid()\n",
    "plt.scatter(x, y1, marker = '.', color = 'r')\n",
    "plt.scatter(x, y2, marker = 'd', color = 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x.reshape(-1, 1)\n",
    "# pipelines: scale X -> SVR\n",
    "svr1 = make_pipeline(StandardScaler(), SVR(kernel=\"linear\", C=100.0, epsilon=0.1))\n",
    "svr2 = make_pipeline(StandardScaler(), SVR(kernel=\"linear\", C=100.0, epsilon=0.1))\n",
    "svr1.fit(X, y1)\n",
    "svr2.fit(X, y2)\n",
    "\n",
    "# predictions for a smooth curve\n",
    "x_fit = np.linspace(0, 5, 400).reshape(-1, 1)\n",
    "y1_hat = svr1.predict(x_fit)\n",
    "y2_hat = svr2.predict(x_fit)\n",
    "\n",
    "plt.scatter(x, y1, s=20, alpha=0.6, label=\"y1 data\")\n",
    "plt.plot(x_fit, y1_hat, label=\"SVR fit y1\")\n",
    "plt.scatter(x, y2, s=20, alpha=0.6, label=\"y2 data\")\n",
    "plt.plot(x_fit, y2_hat, label=\"SVR fit y2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two datasets into one with labels:\n",
    "X_cls = np.vstack([\n",
    "    np.column_stack([x, y1]),  # class 0\n",
    "    np.column_stack([x, y2])   # class 1\n",
    "])\n",
    "y_cls = np.hstack([np.zeros(N, dtype=int), np.ones(N, dtype=int)])\n",
    "\n",
    "# --- linear SVM classifier ---\n",
    "clf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel=\"linear\", C=1.0, random_state=0)\n",
    ")\n",
    "clf.fit(X_cls, y_cls)\n",
    "\n",
    "# Extract separating line in original (x,y) space:\n",
    "# For a linear SVM, decision function: w1*x + w2*y + b = 0  =>  y = -(w1/w2)*x - b/w2\n",
    "# Coefficients live *after* the scaler; to get a readable line in original units,\n",
    "# we can sample x and get the boundary by solving decision_function=0 numerically.\n",
    "# Simpler: compute w,b in scaled space, but draw by transforming points through pipeline.\n",
    "# We'll just compute on a dense grid in original space.\n",
    "\n",
    "xx = np.linspace(0, 5, 400)\n",
    "# For each xx, find yy on the boundary by solving w1*x + w2*y + b = 0 in *scaled* space.\n",
    "# We'll transform points (x, y_guess) iteratively; but easier is to use the analytic form:\n",
    "# Get w,b in scaled feature space:\n",
    "svm = clf.named_steps[\"svc\"]\n",
    "scaler = clf.named_steps[\"standardscaler\"]\n",
    "\n",
    "w = svm.coef_[0]\n",
    "b = svm.intercept_[0]\n",
    "\n",
    "# To draw the boundary in original coordinates, we can use the fact that:\n",
    "# z = (X - mean)/scale; let X=[x, y].\n",
    "# Then w·z + b = 0 => w1*(x-μx)/sx + w2*(y-μy)/sy + b = 0\n",
    "# Solve for y:\n",
    "# y = μy - (sy/w2) * [ w1*(x-μx)/sx + b ]\n",
    "mux, muy = scaler.mean_\n",
    "sx, sy = scaler.scale_\n",
    "\n",
    "# Handle the (unlikely) case w2 ~ 0\n",
    "if abs(w[1]) < 1e-12:\n",
    "    # vertical-like boundary (rare here); skip drawing\n",
    "    yy = np.full_like(xx, np.nan)\n",
    "else:\n",
    "    yy = muy - (sy / w[1]) * (w[0] * (xx - mux) / sx + b)\n",
    "\n",
    "# --- plot ---\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.plot(x, y1base, label=\"original class 0 w/o noise (y1base)\")\n",
    "plt.scatter(x, y1, s=20, alpha=0.7, label=\"class 0 (y1)\")\n",
    "\n",
    "plt.plot(x, y2base, label=\"original class 1 w/o noise (y2base)\")\n",
    "plt.scatter(x, y2, s=20, alpha=0.7, label=\"class 1 (y2)\")\n",
    "\n",
    "plt.plot(xx, yy, \"k--\", lw=4, label=\"SVM linear boundary\")\n",
    "plt.xlim(0, 5)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(\"Linear SVM separating line between the two datasets\")\n",
    "plt.show()\n",
    "\n",
    "if abs(w[1]) >= 1e-12:\n",
    "    m = - (sy / w[1]) * (w[0] / sx)\n",
    "    c = muy - (sy / w[1]) * b + (sy / w[1]) * (w[0]*mux / sx)\n",
    "    print(f\"Decision boundary (original space):  y = {m:.3f} * x + {c:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
